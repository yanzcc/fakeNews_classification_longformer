{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc555a76",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-06T23:16:38.422642600Z",
     "start_time": "2024-05-06T23:16:28.275806500Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\16784\\PycharmProjects\\fakeNews\\.venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f315b317caa04dc2baf97e184ff29126"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\16784\\PycharmProjects\\fakeNews\\.venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:157: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\16784\\.cache\\huggingface\\hub\\models--allenai--longformer-base-4096. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "df_fake = pd.read_csv(r\"C:\\Users\\16784\\Downloads\\archive (3)\\Fake.csv\")\n",
    "df_true = pd.read_csv(r\"C:\\Users\\16784\\Downloads\\archive (3)\\True.csv\")\n",
    "\n",
    "from transformers import LongformerTokenizer\n",
    "\n",
    "# Load RoBERTa tokenizer\n",
    "tokenizer = LongformerTokenizer.from_pretrained(\"allenai/longformer-base-4096\")\n",
    "\n",
    "# Concatenate title and text columns\n",
    "df_fake['input_text'] = df_fake['title'] + \" \" + df_fake['text']\n",
    "df_true['input_text'] = df_true['title'] + \" \" + df_true['text']\n",
    "\n",
    "import re\n",
    "\n",
    "def clean_text(text):\n",
    "    # Remove HTML tags\n",
    "    cleaned_text = re.sub('<.*?>', '', text)\n",
    "    # Remove special characters, punctuation, and non-alphanumeric characters\n",
    "    cleaned_text = re.sub(r'[^\\w\\s]', '', cleaned_text)\n",
    "    # Remove extra whitespaces\n",
    "    cleaned_text = re.sub(r'\\s+', ' ', cleaned_text)\n",
    "    # To lower case\n",
    "    cleaned_text = cleaned_text.lower()\n",
    "    return cleaned_text\n",
    "\n",
    "df_fake['input_text'] = df_fake['input_text'].apply(clean_text)\n",
    "df_true['input_text'] = df_true['input_text'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4121803",
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2024-05-06T23:18:21.417215300Z",
     "start_time": "2024-05-06T23:16:47.989391900Z"
    }
   },
   "outputs": [],
   "source": [
    "def tokenize_and_encode(text):\n",
    "    # Tokenize and encode text with padding, truncation, and set the return type to PyTorch tensor\n",
    "    tokens = tokenizer(text, padding=\"max_length\", truncation=True, max_length=4096, return_tensors=\"pt\")\n",
    "\n",
    "    # Initialize a global attention mask and set global attention on the first token\n",
    "    tokens['global_attention_mask'] = torch.zeros_like(tokens['attention_mask'])\n",
    "    tokens['global_attention_mask'][:, 0] = 1  # Typically, global attention on the first token\n",
    "\n",
    "    return {\n",
    "        'input_ids': tokens['input_ids'][0],  # Extract the tensor from the batch\n",
    "        'attention_mask': tokens['attention_mask'][0],\n",
    "        'global_attention_mask': tokens['global_attention_mask'][0]\n",
    "    }\n",
    "\n",
    "df_fake['encoded_text'] = df_fake['input_text'].apply(tokenize_and_encode)\n",
    "df_true['encoded_text'] = df_true['input_text'].apply(tokenize_and_encode)\n",
    "\n",
    "# Create labels\n",
    "df_fake['label'] = 0  # Fake news\n",
    "df_true['label'] = 1  # True news\n",
    "\n",
    "df = pd.concat([df_fake, df_true], axis = 0, ignore_index = True)\n",
    "\n",
    "\n",
    "\n",
    "df_shuffled = df.sample(frac=1).reset_index(drop=True) # shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f1bce0d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-06T23:18:31.835826800Z",
     "start_time": "2024-05-06T23:18:21.417215300Z"
    }
   },
   "outputs": [],
   "source": [
    "def tensor_to_list(row):\n",
    "    return {\n",
    "        'input_ids': row['input_ids'].tolist(),\n",
    "        'attention_mask': row['attention_mask'].tolist(),\n",
    "        'global_attention_mask': row['global_attention_mask'].tolist()\n",
    "    }\n",
    "\n",
    "# Apply the function to the dataframe\n",
    "df_shuffled['encoded_text'] = df_shuffled['encoded_text'].apply(tensor_to_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c6c25fa5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-06T23:18:31.851724800Z",
     "start_time": "2024-05-06T23:18:31.837825900Z"
    }
   },
   "outputs": [],
   "source": [
    "df_shuffled = df_shuffled[['encoded_text', 'label']]"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# the dataset is too big to fine tune so only sample 5% of them for testing purpose\n",
    "df_shuffled = df_shuffled.sample(frac=1/20, random_state=42) "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T23:18:34.121174700Z",
     "start_time": "2024-05-06T23:18:31.846723700Z"
    }
   },
   "id": "4d403d7c73843955",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d9d2f1cd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-06T23:18:34.127495900Z",
     "start_time": "2024-05-06T23:18:34.121174700Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define split ratios\n",
    "train_size = int(0.8 * len(df_shuffled))\n",
    "valid_size = int(0.1 * len(df_shuffled))\n",
    "\n",
    "# Split the data\n",
    "train_df = df_shuffled[:train_size]\n",
    "valid_df = df_shuffled[train_size:train_size + valid_size]\n",
    "test_df = df_shuffled[train_size + valid_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5864de35",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-06T23:18:34.139855900Z",
     "start_time": "2024-05-06T23:18:34.124497Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                                            encoded_text  label\n22216  {'input_ids': [0, 20125, 12297, 727, 330, 31, ...      0\n27917  {'input_ids': [0, 4892, 5367, 4385, 5299, 7661...      0\n25007  {'input_ids': [0, 309, 7, 5, 92, 1104, 790, 83...      0\n1377   {'input_ids': [0, 40018, 61, 1939, 1984, 1240,...      0\n32476  {'input_ids': [0, 16111, 106, 160, 50, 582, 13...      0\n...                                                  ...    ...\n29200  {'input_ids': [0, 611, 1243, 19288, 1926, 449,...      1\n37723  {'input_ids': [0, 4897, 1494, 16857, 4267, 7, ...      1\n39900  {'input_ids': [0, 3916, 3141, 6344, 1263, 7, 1...      0\n8040   {'input_ids': [0, 38060, 26066, 1637, 397, 579...      1\n6912   {'input_ids': [0, 29, 44856, 4709, 873, 493, 1...      1\n\n[1796 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>encoded_text</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>22216</th>\n      <td>{'input_ids': [0, 20125, 12297, 727, 330, 31, ...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>27917</th>\n      <td>{'input_ids': [0, 4892, 5367, 4385, 5299, 7661...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>25007</th>\n      <td>{'input_ids': [0, 309, 7, 5, 92, 1104, 790, 83...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1377</th>\n      <td>{'input_ids': [0, 40018, 61, 1939, 1984, 1240,...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>32476</th>\n      <td>{'input_ids': [0, 16111, 106, 160, 50, 582, 13...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>29200</th>\n      <td>{'input_ids': [0, 611, 1243, 19288, 1926, 449,...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>37723</th>\n      <td>{'input_ids': [0, 4897, 1494, 16857, 4267, 7, ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>39900</th>\n      <td>{'input_ids': [0, 3916, 3141, 6344, 1263, 7, 1...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>8040</th>\n      <td>{'input_ids': [0, 38060, 26066, 1637, 397, 579...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>6912</th>\n      <td>{'input_ids': [0, 29, 44856, 4709, 873, 493, 1...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>1796 rows × 2 columns</p>\n</div>"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "514af225",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-06T23:18:35.030077Z",
     "start_time": "2024-05-06T23:18:34.139855900Z"
    }
   },
   "outputs": [],
   "source": [
    "def df_to_jsonlines(df, filename):\n",
    "    \"\"\" Convert DataFrame to JSONLines file format \"\"\"\n",
    "    df.to_json(filename, orient='records', lines=True)\n",
    "\n",
    "# Convert datasets to JSONLines\n",
    "df_to_jsonlines(train_df, 'train.jsonl')\n",
    "df_to_jsonlines(valid_df, 'valid.jsonl')\n",
    "df_to_jsonlines(test_df, 'test.jsonl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8c654fd3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NoCredentialsError",
     "evalue": "Unable to locate credentials",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNoCredentialsError\u001B[0m                        Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[14], line 12\u001B[0m\n\u001B[0;32m      9\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m response\n\u001B[0;32m     11\u001B[0m \u001B[38;5;66;03m# Upload the training data\u001B[39;00m\n\u001B[1;32m---> 12\u001B[0m upload_file_to_s3(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtrain.jsonl\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mfakenewspj\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124minput/train.jsonl\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m     13\u001B[0m upload_file_to_s3(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mvalid.jsonl\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mfakenewspj\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124minput/valid.jsonl\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m     14\u001B[0m upload_file_to_s3(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtest.jsonl\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mfakenewspj\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124minput/test.jsonl\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "Cell \u001B[1;32mIn[14], line 8\u001B[0m, in \u001B[0;36mupload_file_to_s3\u001B[1;34m(file_name, bucket, object_name)\u001B[0m\n\u001B[0;32m      6\u001B[0m     object_name \u001B[38;5;241m=\u001B[39m file_name\n\u001B[0;32m      7\u001B[0m s3_client \u001B[38;5;241m=\u001B[39m boto3\u001B[38;5;241m.\u001B[39mclient(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124ms3\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m----> 8\u001B[0m response \u001B[38;5;241m=\u001B[39m s3_client\u001B[38;5;241m.\u001B[39mupload_file(file_name, bucket, object_name)\n\u001B[0;32m      9\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m response\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\boto3\\s3\\inject.py:145\u001B[0m, in \u001B[0;36mupload_file\u001B[1;34m(self, Filename, Bucket, Key, ExtraArgs, Callback, Config)\u001B[0m\n\u001B[0;32m    110\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Upload a file to an S3 object.\u001B[39;00m\n\u001B[0;32m    111\u001B[0m \n\u001B[0;32m    112\u001B[0m \u001B[38;5;124;03mUsage::\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    142\u001B[0m \u001B[38;5;124;03m    transfer.\u001B[39;00m\n\u001B[0;32m    143\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    144\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m S3Transfer(\u001B[38;5;28mself\u001B[39m, Config) \u001B[38;5;28;01mas\u001B[39;00m transfer:\n\u001B[1;32m--> 145\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m transfer\u001B[38;5;241m.\u001B[39mupload_file(\n\u001B[0;32m    146\u001B[0m         filename\u001B[38;5;241m=\u001B[39mFilename,\n\u001B[0;32m    147\u001B[0m         bucket\u001B[38;5;241m=\u001B[39mBucket,\n\u001B[0;32m    148\u001B[0m         key\u001B[38;5;241m=\u001B[39mKey,\n\u001B[0;32m    149\u001B[0m         extra_args\u001B[38;5;241m=\u001B[39mExtraArgs,\n\u001B[0;32m    150\u001B[0m         callback\u001B[38;5;241m=\u001B[39mCallback,\n\u001B[0;32m    151\u001B[0m     )\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\boto3\\s3\\transfer.py:371\u001B[0m, in \u001B[0;36mS3Transfer.upload_file\u001B[1;34m(self, filename, bucket, key, callback, extra_args)\u001B[0m\n\u001B[0;32m    367\u001B[0m future \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_manager\u001B[38;5;241m.\u001B[39mupload(\n\u001B[0;32m    368\u001B[0m     filename, bucket, key, extra_args, subscribers\n\u001B[0;32m    369\u001B[0m )\n\u001B[0;32m    370\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 371\u001B[0m     future\u001B[38;5;241m.\u001B[39mresult()\n\u001B[0;32m    372\u001B[0m \u001B[38;5;66;03m# If a client error was raised, add the backwards compatibility layer\u001B[39;00m\n\u001B[0;32m    373\u001B[0m \u001B[38;5;66;03m# that raises a S3UploadFailedError. These specific errors were only\u001B[39;00m\n\u001B[0;32m    374\u001B[0m \u001B[38;5;66;03m# ever thrown for upload_parts but now can be thrown for any related\u001B[39;00m\n\u001B[0;32m    375\u001B[0m \u001B[38;5;66;03m# client error.\u001B[39;00m\n\u001B[0;32m    376\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m ClientError \u001B[38;5;28;01mas\u001B[39;00m e:\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\s3transfer\\futures.py:103\u001B[0m, in \u001B[0;36mTransferFuture.result\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m     98\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mresult\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m     99\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m    100\u001B[0m         \u001B[38;5;66;03m# Usually the result() method blocks until the transfer is done,\u001B[39;00m\n\u001B[0;32m    101\u001B[0m         \u001B[38;5;66;03m# however if a KeyboardInterrupt is raised we want want to exit\u001B[39;00m\n\u001B[0;32m    102\u001B[0m         \u001B[38;5;66;03m# out of this and propagate the exception.\u001B[39;00m\n\u001B[1;32m--> 103\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_coordinator\u001B[38;5;241m.\u001B[39mresult()\n\u001B[0;32m    104\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyboardInterrupt\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    105\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcancel()\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\s3transfer\\futures.py:266\u001B[0m, in \u001B[0;36mTransferCoordinator.result\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    263\u001B[0m \u001B[38;5;66;03m# Once done waiting, raise an exception if present or return the\u001B[39;00m\n\u001B[0;32m    264\u001B[0m \u001B[38;5;66;03m# final result.\u001B[39;00m\n\u001B[0;32m    265\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_exception:\n\u001B[1;32m--> 266\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_exception\n\u001B[0;32m    267\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_result\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\s3transfer\\tasks.py:139\u001B[0m, in \u001B[0;36mTask.__call__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    135\u001B[0m     \u001B[38;5;66;03m# If the task is not done (really only if some other related\u001B[39;00m\n\u001B[0;32m    136\u001B[0m     \u001B[38;5;66;03m# task to the TransferFuture had failed) then execute the task's\u001B[39;00m\n\u001B[0;32m    137\u001B[0m     \u001B[38;5;66;03m# main() method.\u001B[39;00m\n\u001B[0;32m    138\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_transfer_coordinator\u001B[38;5;241m.\u001B[39mdone():\n\u001B[1;32m--> 139\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_execute_main(kwargs)\n\u001B[0;32m    140\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    141\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_log_and_set_exception(e)\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\s3transfer\\tasks.py:162\u001B[0m, in \u001B[0;36mTask._execute_main\u001B[1;34m(self, kwargs)\u001B[0m\n\u001B[0;32m    159\u001B[0m \u001B[38;5;66;03m# Log what is about to be executed.\u001B[39;00m\n\u001B[0;32m    160\u001B[0m logger\u001B[38;5;241m.\u001B[39mdebug(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mExecuting task \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m with kwargs \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mkwargs_to_display\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m--> 162\u001B[0m return_value \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_main(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    163\u001B[0m \u001B[38;5;66;03m# If the task is the final task, then set the TransferFuture's\u001B[39;00m\n\u001B[0;32m    164\u001B[0m \u001B[38;5;66;03m# value to the return value from main().\u001B[39;00m\n\u001B[0;32m    165\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_is_final:\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\s3transfer\\tasks.py:348\u001B[0m, in \u001B[0;36mCreateMultipartUploadTask._main\u001B[1;34m(self, client, bucket, key, extra_args)\u001B[0m\n\u001B[0;32m    338\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    339\u001B[0m \u001B[38;5;124;03m:param client: The client to use when calling CreateMultipartUpload\u001B[39;00m\n\u001B[0;32m    340\u001B[0m \u001B[38;5;124;03m:param bucket: The name of the bucket to upload to\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    345\u001B[0m \u001B[38;5;124;03m:returns: The upload id of the multipart upload\u001B[39;00m\n\u001B[0;32m    346\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    347\u001B[0m \u001B[38;5;66;03m# Create the multipart upload.\u001B[39;00m\n\u001B[1;32m--> 348\u001B[0m response \u001B[38;5;241m=\u001B[39m client\u001B[38;5;241m.\u001B[39mcreate_multipart_upload(\n\u001B[0;32m    349\u001B[0m     Bucket\u001B[38;5;241m=\u001B[39mbucket, Key\u001B[38;5;241m=\u001B[39mkey, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mextra_args\n\u001B[0;32m    350\u001B[0m )\n\u001B[0;32m    351\u001B[0m upload_id \u001B[38;5;241m=\u001B[39m response[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mUploadId\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[0;32m    353\u001B[0m \u001B[38;5;66;03m# Add a cleanup if the multipart upload fails at any point.\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\botocore\\client.py:565\u001B[0m, in \u001B[0;36mClientCreator._create_api_method.<locals>._api_call\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m    561\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(\n\u001B[0;32m    562\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mpy_operation_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m() only accepts keyword arguments.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    563\u001B[0m     )\n\u001B[0;32m    564\u001B[0m \u001B[38;5;66;03m# The \"self\" in this scope is referring to the BaseClient.\u001B[39;00m\n\u001B[1;32m--> 565\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_make_api_call(operation_name, kwargs)\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\botocore\\client.py:1001\u001B[0m, in \u001B[0;36mBaseClient._make_api_call\u001B[1;34m(self, operation_name, api_params)\u001B[0m\n\u001B[0;32m    997\u001B[0m     maybe_compress_request(\n\u001B[0;32m    998\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmeta\u001B[38;5;241m.\u001B[39mconfig, request_dict, operation_model\n\u001B[0;32m    999\u001B[0m     )\n\u001B[0;32m   1000\u001B[0m     apply_request_checksum(request_dict)\n\u001B[1;32m-> 1001\u001B[0m     http, parsed_response \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_make_request(\n\u001B[0;32m   1002\u001B[0m         operation_model, request_dict, request_context\n\u001B[0;32m   1003\u001B[0m     )\n\u001B[0;32m   1005\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmeta\u001B[38;5;241m.\u001B[39mevents\u001B[38;5;241m.\u001B[39memit(\n\u001B[0;32m   1006\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mafter-call.\u001B[39m\u001B[38;5;132;01m{service_id}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;132;01m{operation_name}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mformat(\n\u001B[0;32m   1007\u001B[0m         service_id\u001B[38;5;241m=\u001B[39mservice_id, operation_name\u001B[38;5;241m=\u001B[39moperation_name\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1012\u001B[0m     context\u001B[38;5;241m=\u001B[39mrequest_context,\n\u001B[0;32m   1013\u001B[0m )\n\u001B[0;32m   1015\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m http\u001B[38;5;241m.\u001B[39mstatus_code \u001B[38;5;241m>\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m300\u001B[39m:\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\botocore\\client.py:1027\u001B[0m, in \u001B[0;36mBaseClient._make_request\u001B[1;34m(self, operation_model, request_dict, request_context)\u001B[0m\n\u001B[0;32m   1025\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_make_request\u001B[39m(\u001B[38;5;28mself\u001B[39m, operation_model, request_dict, request_context):\n\u001B[0;32m   1026\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m-> 1027\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_endpoint\u001B[38;5;241m.\u001B[39mmake_request(operation_model, request_dict)\n\u001B[0;32m   1028\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m   1029\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmeta\u001B[38;5;241m.\u001B[39mevents\u001B[38;5;241m.\u001B[39memit(\n\u001B[0;32m   1030\u001B[0m             \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mafter-call-error.\u001B[39m\u001B[38;5;132;01m{service_id}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;132;01m{operation_name}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mformat(\n\u001B[0;32m   1031\u001B[0m                 service_id\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_service_model\u001B[38;5;241m.\u001B[39mservice_id\u001B[38;5;241m.\u001B[39mhyphenize(),\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1035\u001B[0m             context\u001B[38;5;241m=\u001B[39mrequest_context,\n\u001B[0;32m   1036\u001B[0m         )\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\botocore\\endpoint.py:119\u001B[0m, in \u001B[0;36mEndpoint.make_request\u001B[1;34m(self, operation_model, request_dict)\u001B[0m\n\u001B[0;32m    113\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mmake_request\u001B[39m(\u001B[38;5;28mself\u001B[39m, operation_model, request_dict):\n\u001B[0;32m    114\u001B[0m     logger\u001B[38;5;241m.\u001B[39mdebug(\n\u001B[0;32m    115\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mMaking request for \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m with params: \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    116\u001B[0m         operation_model,\n\u001B[0;32m    117\u001B[0m         request_dict,\n\u001B[0;32m    118\u001B[0m     )\n\u001B[1;32m--> 119\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_send_request(request_dict, operation_model)\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\botocore\\endpoint.py:198\u001B[0m, in \u001B[0;36mEndpoint._send_request\u001B[1;34m(self, request_dict, operation_model)\u001B[0m\n\u001B[0;32m    196\u001B[0m context \u001B[38;5;241m=\u001B[39m request_dict[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcontext\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[0;32m    197\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_update_retries_context(context, attempts)\n\u001B[1;32m--> 198\u001B[0m request \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcreate_request(request_dict, operation_model)\n\u001B[0;32m    199\u001B[0m success_response, exception \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_response(\n\u001B[0;32m    200\u001B[0m     request, operation_model, context\n\u001B[0;32m    201\u001B[0m )\n\u001B[0;32m    202\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_needs_retry(\n\u001B[0;32m    203\u001B[0m     attempts,\n\u001B[0;32m    204\u001B[0m     operation_model,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    207\u001B[0m     exception,\n\u001B[0;32m    208\u001B[0m ):\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\botocore\\endpoint.py:134\u001B[0m, in \u001B[0;36mEndpoint.create_request\u001B[1;34m(self, params, operation_model)\u001B[0m\n\u001B[0;32m    130\u001B[0m     service_id \u001B[38;5;241m=\u001B[39m operation_model\u001B[38;5;241m.\u001B[39mservice_model\u001B[38;5;241m.\u001B[39mservice_id\u001B[38;5;241m.\u001B[39mhyphenize()\n\u001B[0;32m    131\u001B[0m     event_name \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mrequest-created.\u001B[39m\u001B[38;5;132;01m{service_id}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;132;01m{op_name}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mformat(\n\u001B[0;32m    132\u001B[0m         service_id\u001B[38;5;241m=\u001B[39mservice_id, op_name\u001B[38;5;241m=\u001B[39moperation_model\u001B[38;5;241m.\u001B[39mname\n\u001B[0;32m    133\u001B[0m     )\n\u001B[1;32m--> 134\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_event_emitter\u001B[38;5;241m.\u001B[39memit(\n\u001B[0;32m    135\u001B[0m         event_name,\n\u001B[0;32m    136\u001B[0m         request\u001B[38;5;241m=\u001B[39mrequest,\n\u001B[0;32m    137\u001B[0m         operation_name\u001B[38;5;241m=\u001B[39moperation_model\u001B[38;5;241m.\u001B[39mname,\n\u001B[0;32m    138\u001B[0m     )\n\u001B[0;32m    139\u001B[0m prepared_request \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprepare_request(request)\n\u001B[0;32m    140\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m prepared_request\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\botocore\\hooks.py:412\u001B[0m, in \u001B[0;36mEventAliaser.emit\u001B[1;34m(self, event_name, **kwargs)\u001B[0m\n\u001B[0;32m    410\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21memit\u001B[39m(\u001B[38;5;28mself\u001B[39m, event_name, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m    411\u001B[0m     aliased_event_name \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_alias_event_name(event_name)\n\u001B[1;32m--> 412\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_emitter\u001B[38;5;241m.\u001B[39memit(aliased_event_name, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\botocore\\hooks.py:256\u001B[0m, in \u001B[0;36mHierarchicalEmitter.emit\u001B[1;34m(self, event_name, **kwargs)\u001B[0m\n\u001B[0;32m    245\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21memit\u001B[39m(\u001B[38;5;28mself\u001B[39m, event_name, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m    246\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    247\u001B[0m \u001B[38;5;124;03m    Emit an event by name with arguments passed as keyword args.\u001B[39;00m\n\u001B[0;32m    248\u001B[0m \n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    254\u001B[0m \u001B[38;5;124;03m             handlers.\u001B[39;00m\n\u001B[0;32m    255\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 256\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_emit(event_name, kwargs)\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\botocore\\hooks.py:239\u001B[0m, in \u001B[0;36mHierarchicalEmitter._emit\u001B[1;34m(self, event_name, kwargs, stop_on_response)\u001B[0m\n\u001B[0;32m    237\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m handler \u001B[38;5;129;01min\u001B[39;00m handlers_to_call:\n\u001B[0;32m    238\u001B[0m     logger\u001B[38;5;241m.\u001B[39mdebug(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mEvent \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m: calling handler \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m'\u001B[39m, event_name, handler)\n\u001B[1;32m--> 239\u001B[0m     response \u001B[38;5;241m=\u001B[39m handler(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    240\u001B[0m     responses\u001B[38;5;241m.\u001B[39mappend((handler, response))\n\u001B[0;32m    241\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m stop_on_response \u001B[38;5;129;01mand\u001B[39;00m response \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\botocore\\signers.py:105\u001B[0m, in \u001B[0;36mRequestSigner.handler\u001B[1;34m(self, operation_name, request, **kwargs)\u001B[0m\n\u001B[0;32m    100\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mhandler\u001B[39m(\u001B[38;5;28mself\u001B[39m, operation_name\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, request\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m    101\u001B[0m     \u001B[38;5;66;03m# This is typically hooked up to the \"request-created\" event\u001B[39;00m\n\u001B[0;32m    102\u001B[0m     \u001B[38;5;66;03m# from a client's event emitter.  When a new request is created\u001B[39;00m\n\u001B[0;32m    103\u001B[0m     \u001B[38;5;66;03m# this method is invoked to sign the request.\u001B[39;00m\n\u001B[0;32m    104\u001B[0m     \u001B[38;5;66;03m# Don't call this method directly.\u001B[39;00m\n\u001B[1;32m--> 105\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msign(operation_name, request)\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\botocore\\signers.py:199\u001B[0m, in \u001B[0;36mRequestSigner.sign\u001B[1;34m(self, operation_name, request, region_name, signing_type, expires_in, signing_name)\u001B[0m\n\u001B[0;32m    196\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    197\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m e\n\u001B[1;32m--> 199\u001B[0m auth\u001B[38;5;241m.\u001B[39madd_auth(request)\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\botocore\\auth.py:418\u001B[0m, in \u001B[0;36mSigV4Auth.add_auth\u001B[1;34m(self, request)\u001B[0m\n\u001B[0;32m    416\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21madd_auth\u001B[39m(\u001B[38;5;28mself\u001B[39m, request):\n\u001B[0;32m    417\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcredentials \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m--> 418\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m NoCredentialsError()\n\u001B[0;32m    419\u001B[0m     datetime_now \u001B[38;5;241m=\u001B[39m datetime\u001B[38;5;241m.\u001B[39mdatetime\u001B[38;5;241m.\u001B[39mutcnow()\n\u001B[0;32m    420\u001B[0m     request\u001B[38;5;241m.\u001B[39mcontext[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtimestamp\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m datetime_now\u001B[38;5;241m.\u001B[39mstrftime(SIGV4_TIMESTAMP)\n",
      "\u001B[1;31mNoCredentialsError\u001B[0m: Unable to locate credentials"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "\n",
    "# Function to upload files to S3\n",
    "def upload_file_to_s3(file_name, bucket, object_name=None):\n",
    "    if object_name is None:\n",
    "        object_name = file_name\n",
    "    s3_client = boto3.client('s3')\n",
    "    response = s3_client.upload_file(file_name, bucket, object_name)\n",
    "    return response\n",
    "\n",
    "# Upload the training data\n",
    "upload_file_to_s3('train.jsonl', 'fakenewspj', 'input/train.jsonl')\n",
    "upload_file_to_s3('valid.jsonl', 'fakenewspj', 'input/valid.jsonl')\n",
    "upload_file_to_s3('test.jsonl', 'fakenewspj', 'input/test.jsonl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d49400d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.0+cpu\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "%pip uninstall torch torchvision torchaudio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "522f367e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
